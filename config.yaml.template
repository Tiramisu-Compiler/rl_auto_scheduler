ray:
    num_workers: 1
    training_iteration: 1000
    ray_num_cpus: 112
    checkpoint_freq: 5
    base_path: "/home/user/rl_autoscheduler"
    name: "Training_multi_enhanced"

environment:
    dataset_path: "./Dataset_multi/"
    programs_file: "./multicomp.json"
    clean_files: True
    json_dataset: 
        # Path to the dataset file
        path: "./Dataset_pickle/full_legality_annotations_solver.pkl"
        # Path to the dataset cpp files
        cpps_path: "./Dataset_multi"
        # Path where to save the updated dataset (without the extension, it will be inferred by the dataset format)
        path_to_save_dataset: "./Dataset_pickle/full_legality_annotations_solver_updated"
        # Supported formats are available int he dataset_utilities module
        dataset_format: "PICKLE"


tiramisu:
    tiramisu_path: "/home/user/tiramisu/" 
    env_type:  "cpu"
    model_checkpoint: "/home/user/model.pt"
    
training:
    train_batch_size: 1024
    sgd_minibatch_size: 256
    lr: 0.0001
    num_sgd_iter: 4

model:
    layer_sizes:
        - 600
        - 350
        - 200
        - 180
    drops:
        - 0.225
        - 0.225
        - 0.225
        - 0.225

defaults:
  - override hydra/launcher: ray